{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":97919,"databundleVersionId":11694977,"sourceType":"competition"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade scipy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:15:58.480505Z","iopub.execute_input":"2025-04-05T12:15:58.480826Z","iopub.status.idle":"2025-04-05T12:16:09.552830Z","shell.execute_reply.started":"2025-04-05T12:15:58.480796Z","shell.execute_reply":"2025-04-05T12:16:09.551978Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy.stats import pearsonr","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T12:16:09.554312Z","iopub.execute_input":"2025-04-05T12:16:09.554663Z","iopub.status.idle":"2025-04-05T12:16:10.050497Z","shell.execute_reply.started":"2025-04-05T12:16:09.554627Z","shell.execute_reply":"2025-04-05T12:16:10.049633Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  Grammar Scoring Engine \n#  Competition Solution\n# Combines Whisper transcription, linguistic features, and XGBoost regression","metadata":{}},{"cell_type":"code","source":"\n# Installing dependencies\n!pip install -qU git+https://github.com/openai/whisper.git\n!pip install -q language-tool-python spacy pandas xgboost matplotlib seaborn scipy\n!python -m spacy download -q en_core_web_sm\n!sudo apt-get install -qq default-jre\n\n\nimport os\nimport torch\nimport whisper\nimport spacy\nimport pandas as pd\nimport numpy as np\nimport language_tool_python\nfrom scipy.stats import pearsonr\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error, r2_score  # Added missing import\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Checking  GPU availability\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:03:02.231453Z","iopub.execute_input":"2025-04-05T13:03:02.231814Z","iopub.status.idle":"2025-04-05T14:02:42.769204Z","shell.execute_reply.started":"2025-04-05T13:03:02.231769Z","shell.execute_reply":"2025-04-05T14:02:42.767963Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 1: Robust Audio Transcription","metadata":{}},{"cell_type":"code","source":"\nclass AudioTranscriber:\n    def __init__(self):\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.model = whisper.load_model(\"base\").to(self.device)\n        self.fp16 = self.device == \"cuda\"\n    \n    def transcribe(self, audio_path):\n        try:\n            result = self.model.transcribe(\n                audio_path,\n                fp16=self.fp16,\n                verbose=None  \n            )\n            return result.get(\"text\", \"\")\n        except Exception as e:\n            print(f\"Transcription failed for {os.path.basename(audio_path)}: {str(e)}\")\n            return \"\"\n\ntranscriber = AudioTranscriber()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Step 2: Comprehensive Feature Engineering","metadata":{}},{"cell_type":"code","source":"\nclass FeatureExtractor:\n    def __init__(self):\n        self.nlp = spacy.load(\"en_core_web_sm\")\n        self.tool = language_tool_python.LanguageTool('en-US')\n        \n    def extract(self, text):\n        features = {}\n        text = text.strip()\n        \n        # Basic text stats\n        features['text_length'] = len(text)\n        features['word_count'] = len(text.split())\n        \n        # Grammar checking\n        if features['word_count'] > 0:\n            try:\n                matches = self.tool.check(text)\n                features['grammar_errors'] = len(matches)\n                features['error_rate'] = len(matches) / features['word_count']\n            except:\n                features.update({'grammar_errors': 0, 'error_rate': 0})\n        else:\n            features.update({'grammar_errors': 0, 'error_rate': 0})\n        \n        # Linguistic features\n        if features['word_count'] > 1:\n            try:\n                doc = self.nlp(text)\n                features.update({\n                    'sentence_count': len(list(doc.sents)),\n                    'avg_sentence_length': features['word_count'] / max(1, len(list(doc.sents))),\n                    'noun_ratio': sum(1 for t in doc if t.pos_ == 'NOUN') / features['word_count'],\n                    'verb_ratio': sum(1 for t in doc if t.pos_ == 'VERB') / features['word_count'],\n                    'punctuation_ratio': sum(1 for t in doc if t.is_punct) / features['word_count'],\n                    'unique_word_ratio': len(set(t.text for t in doc)) / features['word_count']\n                })\n            except:\n                features.update({\n                    'sentence_count': 0,\n                    'avg_sentence_length': 0,\n                    'noun_ratio': 0,\n                    'verb_ratio': 0,\n                    'punctuation_ratio': 0,\n                    'unique_word_ratio': 0\n                })\n        else:\n            features.update({\n                'sentence_count': 0,\n                'avg_sentence_length': 0,\n                'noun_ratio': 0,\n                'verb_ratio': 0,\n                'punctuation_ratio': 0,\n                'unique_word_ratio': 0\n            })\n            \n        return features\n\nfeature_extractor = FeatureExtractor()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  Step 3: Data Pipeline","metadata":{}},{"cell_type":"code","source":"\nclass DataProcessor:\n    def __init__(self):\n        self.scaler = StandardScaler()\n        \n    def process(self, csv_path, audio_dir, is_train=True):\n        df = pd.read_csv(csv_path)\n        features = []\n        \n        for idx, row in df.iterrows():\n            audio_path = os.path.join(audio_dir, row['filename'])\n            try:\n                text = transcriber.transcribe(audio_path)\n                feat = feature_extractor.extract(text)\n                if is_train:\n                    feat['label'] = row['label']  # Fixed column name\n                features.append(feat)\n            except Exception as e:\n                print(f\"Skipping {row['filename']}: {str(e)}\")\n                features.append(self.empty_features(is_train))\n            \n            # Memory management\n            if idx % 10 == 0 and torch.cuda.is_available():\n                torch.cuda.empty_cache()\n                \n        features_df = pd.DataFrame(features).fillna(0)\n        if is_train:\n            features_df = features_df[features_df['word_count'] > 0]\n            \n        return features_df\n    \n    def empty_features(self, is_train):\n        base = {\n            'text_length': 0,\n            'word_count': 0,\n            'grammar_errors': 0,\n            'error_rate': 0,\n            'sentence_count': 0,\n            'avg_sentence_length': 0,\n            'noun_ratio': 0,\n            'verb_ratio': 0,\n            'punctuation_ratio': 0,\n            'unique_word_ratio': 0\n        }\n        if is_train:\n            base['grammar_score'] = 1.0  \n        return base\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n# Step 4: Model Training","metadata":{}},{"cell_type":"code","source":"\nclass GrammarScorer:\n    def __init__(self):\n        self.model = xgb.XGBRegressor(\n            objective='reg:squarederror',\n            n_estimators=300,\n            max_depth=6,\n            learning_rate=0.05,\n            subsample=0.8,\n            colsample_bytree=0.8,\n            tree_method='gpu_hist' if torch.cuda.is_available() else 'hist',\n            predictor='gpu_predictor' if torch.cuda.is_available() else 'cpu_predictor',\n            random_state=42\n        )\n        \n    def train(self, X_train, y_train, X_val, y_val):\n        self.model.fit(\n            X_train, y_train,\n            eval_set=[(X_val, y_val)],\n            early_stopping_rounds=20,\n            verbose=False\n        )\n        \n    def evaluate(self, X, y):\n        pred = self.model.predict(X)\n        pearson, _ = pearsonr(y, pred)\n        mse = mean_squared_error(y, pred)\n        r2 = r2_score(y, pred)\n        print(f\"Pearson: {pearson:.3f} | MSE: {mse:.3f} | RÂ²: {r2:.3f}\")\n        return pearson, mse, r2\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n#  Main Execution Flow","metadata":{}},{"cell_type":"code","source":"\n# Initializing components\nprocessor = DataProcessor()\nscorer = GrammarScorer()\n\n# Processing training data\nprint(\"Processing training data...\")\ntrain_df = processor.process(\n    '/kaggle/input/shl-intern-hiring-assessment/dataset/train.csv',  \n    '/kaggle/input/shl-intern-hiring-assessment/dataset/audios_train'  \n)\n\n# Preparing data\nX = train_df.drop(columns=['label'])\ny = train_df['label']\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Training model\nprint(\"\\nTraining model...\")\nscorer.train(X_train, y_train, X_val, y_val)\n\n# Evaluating\nprint(\"\\nValidation performance:\")\nscorer.evaluate(X_val, y_val)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n#  Visualization & Interpretation","metadata":{}},{"cell_type":"code","source":"\n# Feature importance\nimportance = pd.DataFrame({\n    'feature': X.columns,\n    'importance': scorer.model.feature_importances_\n}).sort_values('importance', ascending=False)\n\nplt.figure(figsize=(12, 8))\nsns.barplot(x='importance', y='feature', data=importance)\nplt.title('Feature Importance Analysis')\nplt.show()\n\n# Prediction distribution\nval_pred = scorer.model.predict(X_val)\nplt.figure(figsize=(10, 6))\nsns.histplot(x=val_pred, bins=20, kde=True)\nplt.title('Predicted Score Distribution')\nplt.xlabel('label')\nplt.show()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n# Generating Submission","metadata":{}},{"cell_type":"code","source":"\nprint(\"Processing test data...\")\ntest_df = processor.process(\n    '/kaggle/input/shl-intern-hiring-assessment/dataset/test.csv', \n    '/kaggle/input/shl-intern-hiring-assessment/dataset/audios_test',  \n    is_train=False\n)\n\n# Predicting and formating\ntest_pred = scorer.model.predict(test_df)\nsubmission = pd.DataFrame({\n    'filename': pd.read_csv('/kaggle/input/shl-intern-hiring-assessment/dataset/test.csv')['filename'],\n    'label': np.clip(test_pred, 1.0, 5.0)  \n})\n\n# Saving\nsubmission.to_csv('submission.csv', index=False)\nprint(\"Submission file saved!\")\n\n# Cleanup\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}